install.packages(c('repr', 'IRdisplay', 'IRkernel'), type = 'source')
IRkernel::installspec()
install.packages("car")
install.packages("car")
install.packages("car")
install.packages("curl")
install.packages("rio")
install.packages("car")
install.packages("manipulate")
library(manipulate)
install.packages("Rcmdr")
library(MASS, lib.loc = "/usr/lib/R/library")
install.packages("RcmdrMisc")
install.packages("car")
install.packages("rio")
install.packages("curl")
.libPaths( c( .libPaths(), "~/R/x86_64-pc-linux-gnu-library") )
install.packages("RcmdrMisc")
install.packages("RcmdrMisc")
install.packages("Rcmdr")
install.packages("car")
library(Rcmdr)
library(MASS)
data("birthwt")
summary(birthwt)
library(car) #for recoding
birthwt$smoke_cat <- recode(birthwt$smoke, '1="YES"; else="NO"', as.factor=TRUE)
birthwt$race_cat <- recode(birthwt$race, '1="white"; 2="black"; 3="other"', as.factor=TRUE)
save(birthwt, file = 'birthwt_recoded.Rdata')
freq_race = table(birthwt$race_cat)
req_race = table(birthwt$race_cat)
freq_race
freq_smoke = table(birthwt$smoke_cat)
freq_smoke
freq_race_and_smoke = table(birthwt$race_cat, birthwt$smoke_cat)
freq_race_and_smoke
prop.table(freq_race_and_smoke, 1)
prop.table(freq_race_and_smoke, 2)
table1 = round(prop.table(freq_race_and_smoke, 1), 2)
table2 = round(prop.table(freq_race_and_smoke, 2)*100, 1)
tapply(birthwt$age, birthwt$race_cat, mean)
tapply(birthwt$age, birthwt$race_cat, median)
data('GBSG2')
??GBSG2
gc_genome_data <- read.csv("~/Sistemu_biologija/1semestras/LinuxOS/Homework/Homework7/yeast-GC/outputs/gc_genome_data.csv")
View(gc_genome_data)
boxplot(gc_genome_data$gc_content~gc_genome_data$Strain)
boxplot(gc_genome_data$gc_content~gc_genome_data$Strain,
xlab = 'Strain', ylab = 'GC content %')
setwd(pwd)
pwd
pwd
dir
wd
getwd
getwd()
gc_content_all_strains <- read.csv("~/Sistemu_biologija/1semestras/LinuxOS/Homework/Homework7/yeast-GC/outputs/gc_content_all_strains.csv", header=FALSE)
View(gc_content_all_strains)
gc_content_all_strains <- read.csv("~/Sistemu_biologija/1semestras/LinuxOS/Homework/Homework7/yeast-GC/outputs/gc_content_all_strains.csv", header=FALSE)
View(gc_content_all_strains)
summary(gc_content_all_strains)
summary(gc_content_all_strains~gc_content_all_strains[,1])
View(gc_content_all_strains)
View(gc_content_all_strains)
gc_content_all_strains_stat <- read.csv("~/Sistemu_biologija/1semestras/LinuxOS/Homework/Homework7/yeast-GC/outputs/gc_content_all_strains_stat.csv")
View(gc_content_all_strains_stat)
summary(gc_content_all_strains_stat)
summary(gc_content_all_strains_stat$strain)
str(gc_content_all_strains_stat)
tapply(gc_content_all_strains_stat$strain, median)
T7_WashU_2011_AFDE01000000 <- read.table("~/Sistemu_biologija/1semestras/LinuxOS/Homework/Homework7/yeast-GC/outputs/T7_WashU_2011_AFDE01000000.gc", quote="\"", comment.char="")
View(T7_WashU_2011_AFDE01000000)
K11_Stanford_2014_JRIJ00000000 <- read.table("~/Sistemu_biologija/1semestras/LinuxOS/Homework/Homework7/yeast-GC/outputs/K11_Stanford_2014_JRIJ00000000.gc", quote="\"", comment.char="")
View(K11_Stanford_2014_JRIJ00000000)
JAY291_Duke_2009_ACFL01000000 <- read.table("~/Sistemu_biologija/1semestras/LinuxOS/Homework/Homework7/yeast-GC/outputs/JAY291_Duke_2009_ACFL01000000.gc", quote="\"", comment.char="")
View(JAY291_Duke_2009_ACFL01000000)
summary(JAY291_Duke_2009_ACFL01000000)
summary(K11_Stanford_2014_JRIJ00000000)
summary(T7_WashU_2011_AFDE01000000)
library (MASS)
library (MASS)
data('birthwt')
str(birthwt)
summary(birthwt)
View(birthwt)
svoris_prad = data('birthwt')
library (MASS)
svoris_prad = data('birthwt')
summary(birthwt)
library (MASS)
svoris_prad = data('birthwt')
summary(svoris_prad )
duom_norm = birthwt
normalize(duom_norm, method = "standardize", range = c(0, 1), margin = 1L, on.constant = "quiet")
??normalize
library(BBmisc)
install.packages("BBmisc")
normalize(duom_norm, method = "standardize", range = c(0, 1), margin = 1L, on.constant = "quiet")
library (MASS)
library(BBmisc)
data('birthwt')
duom_norm = birthwt
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
normalize(duom_norm, method = "standardize", range = c(0, 1), margin = 1L, on.constant = "quiet")
normalize(duom_norm$.)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
normalize(duom_norm$.)
normalize(duom_norm[:])
normalize(duom_norm)
summary(duom_norm)
norma = normalize(duom_norm)
summary(norma)
colnames(duom_norm)
for (name in colnames(duom_norm)){
print(name)
}
for (name in colnames(duom_norm)){
normalize(duom_norm$name)
}
warnings()
is.na(duom_norm)
summary(duom_norm)
?normalize
library (MASS)
library(BBmisc)
data('birthwt')
duom_norm = birthwt
for (name in colnames(duom_norm)){
normalize(duom_norm$name)
}
View(duom_norm)
normalize(duom_norm)
View(duom_norm)
for (name in colnames(duom_norm)){
norma$name=normalize(duom_norm$name)
}
for (name in colnames(duom_norm)){
norma$name=normalize(duom_norm$name, method = "standardize", range = c(0, 1), margin = 1L, on.constant = "quiet")
}
View(duom_norm)
normalize(duom_norm$age, method = "standardize", range = c(0, 1), margin = 1L, on.constant = "quiet")
View(duom_norm)
norma$age = normalize(duom_norm$age, method = "standardize", range = c(0, 1), margin = 1L, on.constant = "quiet")
norma =[]
norma = []
norma = c()
norma$age = normalize(duom_norm$age, method = "standardize", range = c(0, 1), margin = 1L, on.constant = "quiet")
View(norma)
duom_norm$age = normalize(duom_norm$age, method = "standardize", range = c(0, 1), margin = 1L, on.constant = "quiet")
View(duom_norm)
norma[["age"]]
?normalize
duom_norm$age = normalize(duom_norm$age, method = "range", range = c(0, 1), margin = 1L, on.constant = "quiet")
library (MASS)
library(BBmisc)
data('birthwt')
duom_norm = birthwt
duom_norm$age = normalize(duom_norm$age, method = "range", range = c(0, 1), margin = 1L, on.constant = "quiet")
library (MASS)
library(BBmisc)
data('birthwt')
duom_norm = birthwt
duom_norm$age = normalize(duom_norm$age, method = "range", range = c(0, 1), margin = 1L, on.constant = "quiet")
View(duom_norm)
duom_norm$name= normalize(duom_norm$name, method = "range", range = c(0, 1), margin = 1L, on.constant = "quiet")
duom_norm$i = normalize(duom_norm$i, method = "range", range = c(0, 1), margin = 1L, on.constant = "quiet")
for (i in colnames(duom_norm)){
duom_norm$i = normalize(duom_norm$i, method = "range", range = c(0, 1), margin = 1L, on.constant = "quiet")
}
View(duom_norm)
duom_norm$. = normalize(duom_norm$., method = "range", range = c(0, 1), margin = 1L, on.constant = "quiet")
duom_norm$. = normalize(duom_norm$., method = "range", range = c(0, 1), margin = 1L, on.constant = "quiet")
for (i in length(colnames(duom_norm))){
duom_norm[i] = normalize(duom_norm[i], method = "range", range = c(0, 1), margin = 1L, on.constant = "quiet")
}
View(duom_norm)
length(colnames(duom_norm)
)
for (i in length(colnames(duom_norm))){
i
}
for (i in length(colnames(duom_norm))){
print(i)
}
for (i in 1:length(colnames(duom_norm))){
print(i)
}
for (i in 1:length(colnames(duom_norm))){
print(i)
duom_norm[i] = normalize(duom_norm[i], method = "range", range = c(0, 1), margin = 1L, on.constant = "quiet")
}
for (i in 1:length(colnames(duom_norm))){
duom_norm[i] = normalize(duom_norm[i], method = "range", range = c(0, 1), margin = 1L, on.constant = "quiet")
}
View(duom_norm)
## The recommended way of running NMDS (Minchin 1987)
##
data(dune)
library(MASS) ## isoMDS
# NMDS
sol <- metaMDS(dune)
sol
plot(sol, type="t")
## Start from previous best solution
sol2 <- metaMDS(dune, previous.best = sol)
## The recommended way of running NMDS (Minchin 1987)
##
library(MASS)
data(dune)
install.packages("vegan")
data(dune)
library(vegan)
data(dune)
## isoMDS
# NMDS
sol <- metaMDS(dune)
sol
a='jdj'
b='sad'
a+b
a <- 3
a=3
install.packages("rgl")
update.packages(oldPkgs="rgl")
# This script is the analyses of mice protein expression data
# Loading data
df = read.csv("../inputs/Data_Cortex_Nuclear.csv")
df_copy = df
# Looking to the structure of the data
summary (df)
# Figuring out how many NAs are there
sum(is.na(df))
# Applying NA filling alorithm
# Missing Value Imputation by Weighted Moving Average
library(imputeTS)
for (i in 1:length(colnames(df[2:78]))){
df[i] = na_ma(df[i], k = 2, weighting = "exponential")
}
# just checking if everything was replaced
sum(is.na(df))
# I decided to work with 2 groups: control mice and trisomic mice
# The variable for calsification is Ganotype
# Normalizing the data
library(BBmisc)
for (i in 2:78){
df[i] = normalize(df[i], method = "range", range = c(0, 1),
margin = 1L, on.constant = "quiet")
}
summary(df)
# Preparing data for crossvalidation
# Since the groups are in order let's mix the rows
df = df[sample(nrow(df)),]
write.csv(df, "../outputs/df.csv")
# And devide the data into 5 data sets
df_1 = df[1:216,]
df_2 = df[217:432,]
df_3 = df[433:648,]
df_4 = df[649:864,]
df_5 = df[865:1080,]
df_all = list(df_1, df_2, df_3, df_4, df_5)
df_index = list(1:216, 217:432, 433:648, 649:864, 865:1080)
write.csv(df_all, "../outputs/df_all.csv")
df_all_index = c(1:5)
kazkas1 = c('a','b','c','d','e')
kazkas2 = c(1,2,3,4,5)
kazkas = list(kazkas1,kazkas2)
kazkas_ind = (1:5)
# Let's try knn
library(class)
for (i in 1:5){
train_data = df[df_index != i,]
write.csv(train_data, "../outputs/train_data.csv")
test_data = df_all[df_all_index == i]
knn_model <- knn(train = train_data[,2:78], test = test_data[],
cl = train_data$Genotype, k = 2)
}
knn_model <- knn(train = dTrain, test = dTest, cl = vTrain, k = kNN)
# PCA for redusing dimentions ??? GAL
library(stats)
library(pca3d)
dfPCA <- prcomp(df[, 2:78])
summary(dfPCA)
plot(dfPCA)
biplot(dfPCA)
str(dfPCA)
pca3d(dfPCA, group)
install.packages("pca3d")
# This script is the analyses of mice protein expression data
# Loading data
df = read.csv("../inputs/Data_Cortex_Nuclear.csv")
# This script is the analyses of mice protein expression data
# Loading data
df = read.csv("../inputs/Data_Cortex_Nuclear.csv")
setwd("~/Sistemu_biologija/1semestras/Data_mining/Peles/analize/bins")
# This script is the analyses of mice protein expression data
# Loading data
df = read.csv("../inputs/Data_Cortex_Nuclear.csv")
df_copy = df
# This script is the analyses of mice protein expression data
# Loading data
df = read.csv("../inputs/Data_Cortex_Nuclear.csv")
df_copy = df
# Looking to the structure of the data
summary (df)
# Figuring out how many NAs are there
sum(is.na(df))
# Applying NA filling alorithm
# Missing Value Imputation by Weighted Moving Average
library(imputeTS)
for (i in 1:length(colnames(df[2:78]))){
df[i] = na_ma(df[i], k = 2, weighting = "exponential")
}
# just checking if everything was replaced
sum(is.na(df))
# I decided to work with 2 groups: control mice and trisomic mice
# The variable for calsification is Ganotype
# Normalizing the data
library(BBmisc)
for (i in 2:78){
df[i] = normalize(df[i], method = "range", range = c(0, 1),
margin = 1L, on.constant = "quiet")
}
summary(df)
# Preparing data for crossvalidation
# Since the groups are in order let's mix the rows
df = df[sample(nrow(df)),]
write.csv(df, "../outputs/df.csv")
# And devide the data into 5 data sets
df_1 = df[1:216,]
df_2 = df[217:432,]
df_3 = df[433:648,]
df_4 = df[649:864,]
df_5 = df[865:1080,]
df_all = list(df_1, df_2, df_3, df_4, df_5)
df_index = list(1:216, 217:432, 433:648, 649:864, 865:1080)
write.csv(df_all, "../outputs/df_all.csv")
df_all_index = c(1:5)
kazkas1 = c('a','b','c','d','e')
kazkas2 = c(1,2,3,4,5)
kazkas = list(kazkas1,kazkas2)
kazkas_ind = (1:5)
# Let's try knn
library(class)
for (i in 1:5){
train_data = df[df_index != i,]
write.csv(train_data, "../outputs/train_data.csv")
test_data = df_all[df_all_index == i]
knn_model <- knn(train = train_data[,2:78], test = test_data[],
cl = train_data$Genotype, k = 2)
}
knn_model <- knn(train = dTrain, test = dTest, cl = vTrain, k = kNN)
# PCA for redusing dimentions ??? GAL
library(stats)
library(pca3d)
dfPCA <- prcomp(df[, 2:78])
summary(dfPCA)
plot(dfPCA)
biplot(dfPCA)
str(dfPCA)
pca3d(dfPCA, group)
kazkas1[c(1,3),]
kazkas1[c(1,3)]
dfPCA <- prcomp(df[, 2:78])
summary(dfPCA)
library(pca3d)
install.packages("pca3d")
